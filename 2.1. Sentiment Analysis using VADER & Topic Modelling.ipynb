{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb = pd.read_csv('https://raw.githubusercontent.com/skathirmani/datasets/master/imdb_sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not sure who was more lost - the flat characte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very little music or anything to speak of.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The best scene in the movie was when Gerardo i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  A very, very, very slow-moving, aimless movie ...          0\n",
       "1  Not sure who was more lost - the flat characte...          0\n",
       "2  Attempting artiness with black & white and cle...          0\n",
       "3       Very little music or anything to speak of.            0\n",
       "4  The best scene in the movie was when Gerardo i...          1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VADER\n",
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valence Aware Dictionary sENTIMENT Reasoner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sentiment = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'compound': 0.6369, 'neg': 0.0, 'neu': 0.192, 'pos': 0.808}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment.polarity_scores('i love india')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7125"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment.polarity_scores('i LOVE india')['compound']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compound calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6369499429264264"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For \"love\" word, normalization is calculated as below:\n",
    "\n",
    "score = 3.2\n",
    "alpha = 15\n",
    "compound = score / np.sqrt(np.square(score)+alpha)\n",
    "compound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'compound': 0.128, 'neg': 0.374, 'neu': 0.202, 'pos': 0.424}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment.polarity_scores('i love india i hate apple')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pos, neg, neu calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.42424242424242425, 0.37373737373737376, 0.20202020202020202)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = 3.2 + 1\n",
    "neg = 2.7 + 1\n",
    "neu = 2\n",
    "total = pos + neg + neu\n",
    "pos/total,neg/total,neu/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12803687993289598"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = (pos - neg)\n",
    "alpha = 15\n",
    "compound = score / np.sqrt(np.square(score)+alpha)\n",
    "compound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(text):\n",
    "    compound = sentiment.polarity_scores(text)['compound']\n",
    "    if compound < 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "imdb['sentiment_vader'] = imdb['review'].apply(get_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7767379679144385"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(imdb['sentiment'],imdb['sentiment_vader'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic Modelling\n",
    "----------\n",
    "- % of topic used in each document\n",
    "- Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LSA\n",
    "- Matrix Factorization\n",
    "- LDA (Latent Dirichlet Allocation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA\n",
    "---------- \n",
    "Document - Term (Main Matrix)\n",
    "- Document - Topic Relationship (Matrix 1)\n",
    "- Topic - Term Relationship (Matrix 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\programdata\\anaconda3\\lib\\site-packages (3.7.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from gensim) (1.14.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from gensim) (1.0.0)\n",
      "Requirement already satisfied: six>=1.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from gensim) (1.11.0)\n",
      "Requirement already satisfied: smart-open>=1.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from gensim) (1.8.0)\n",
      "Requirement already satisfied: bz2file in c:\\programdata\\anaconda3\\lib\\site-packages (from smart-open>=1.7.0->gensim) (0.98)\n",
      "Requirement already satisfied: boto>=2.32 in c:\\programdata\\anaconda3\\lib\\site-packages (from smart-open>=1.7.0->gensim) (2.48.0)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from smart-open>=1.7.0->gensim) (2.18.4)\n",
      "Requirement already satisfied: boto3 in c:\\programdata\\anaconda3\\lib\\site-packages (from smart-open>=1.7.0->gensim) (1.9.86)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.7.0->gensim) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.7.0->gensim) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.7.0->gensim) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.7.0->gensim) (2018.1.18)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from boto3->smart-open>=1.7.0->gensim) (0.9.3)\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.86 in c:\\programdata\\anaconda3\\lib\\site-packages (from boto3->smart-open>=1.7.0->gensim) (1.12.86)\n",
      "Requirement already satisfied: s3transfer<0.2.0,>=0.1.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from boto3->smart-open>=1.7.0->gensim) (0.1.13)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in c:\\programdata\\anaconda3\\lib\\site-packages (from botocore<1.13.0,>=1.12.86->boto3->smart-open>=1.7.0->gensim) (2.6.1)\n",
      "Requirement already satisfied: docutils>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from botocore<1.13.0,>=1.12.86->boto3->smart-open>=1.7.0->gensim) (0.14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 18.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 8)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon = pd.read_csv('amazon_reviews_big.csv')\n",
    "amazon.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    What I recieved is not what is pictured here O...\n",
       "1    Excellent unit and a pretty simple install usi...\n",
       "2    I'm enjoying this keyboard, I'm getting anothe...\n",
       "3    Overall, this is a fantastic camera that I'm e...\n",
       "4    These work very well with mySamsung PN64D7000 ...\n",
       "Name: reviewText, dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon['reviewText'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = amazon['reviewText'].fillna('').str.lower()\n",
    "docs = docs.str.replace('[^a-z ]','')\n",
    "\n",
    "docs_clean = []\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "stopwords.extend(['','use','one','like','work'])\n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "for doc in docs:\n",
    "    words = doc.split(' ')\n",
    "    words_clean = [stemmer.stem(word) for word in words if word not in stopwords]\n",
    "    words_clean = [word for word in words_clean if word not in stopwords]\n",
    "    docs_clean.append(words_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['reciev', 'pictur', 'advert', 'vidio', 'cabl']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_clean[0][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "dictionary = gensim.corpora.Dictionary(docs_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(152945, 152945)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(dictionary.values())),len(list(dictionary.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'advert'), (1, 'amazoncom'), (2, 'anyth'), (3, 'attempt'), (4, 'back')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(dictionary.keys(),dictionary.values()))[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1), (1, 2), (2, 1), (3, 1), (4, 1)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.doc2bow(docs_clean[0])[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_bow = []\n",
    "for doc in docs_clean:\n",
    "    bow = dictionary.doc2bow(doc)\n",
    "    docs_bow.append(bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(0, 1), (1, 2), (2, 1), (3, 1), (4, 1)],\n",
       " [(27, 1), (34, 1), (49, 1), (52, 1), (53, 1)],\n",
       " [(6, 2), (20, 1), (21, 3), (29, 1), (41, 1)])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_bow[0][0:5],docs_bow[1][0:5],docs_bow[2][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaModel(docs_bow,\n",
    "                                  id2word = dictionary,\n",
    "                                  num_topics = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(0, 0.4490993), (1, 0.049294174), (5, 0.23619917), (7, 0.2574524)],\n",
       " [(1, 0.1801925), (2, 0.47745797), (5, 0.33116606)],\n",
       " [(1, 0.03998171), (6, 0.9421356)])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output format(Topic_type, % of words in that Topic)\n",
    "lda_model.get_document_topics(docs_bow[0]),lda_model.get_document_topics(docs_bow[1]),lda_model.get_document_topics(docs_bow[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2topic = pd.DataFrame(lda_model.get_document_topics(docs_bow[0]),\n",
    "            columns = ['topic_no','prob'])\n",
    "doc2topic.sort_values('prob', ascending = False).iloc[0]['topic_no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = []\n",
    "for bow in docs_bow:\n",
    "    doc2topic = pd.DataFrame(lda_model.get_document_topics(docs_bow[0]),\n",
    "            columns = ['topic_no','prob'])\n",
    "    topic = doc2topic.sort_values('prob', ascending = False)\n",
    "    topic = topic.iloc[0]['topic_no']\n",
    "    topics.append(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 100000)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics[0:10],len(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.024*\"cabl\" + 0.016*\"connect\" + 0.015*\"batteri\" + 0.014*\"devic\" + 0.012*\"charg\" + 0.010*\"power\" + 0.009*\"plug\" + 0.009*\"need\" + 0.008*\"router\" + 0.007*\"adapt\"'),\n",
       " (1,\n",
       "  '0.023*\"tv\" + 0.021*\"speaker\" + 0.015*\"sound\" + 0.011*\"set\" + 0.010*\"player\" + 0.010*\"video\" + 0.009*\"play\" + 0.009*\"qualiti\" + 0.008*\"pictur\" + 0.008*\"great\"'),\n",
       " (2,\n",
       "  '0.025*\"case\" + 0.012*\"fit\" + 0.010*\"ipad\" + 0.009*\"well\" + 0.009*\"cover\" + 0.009*\"screen\" + 0.008*\"look\" + 0.008*\"protect\" + 0.008*\"would\" + 0.007*\"nice\"'),\n",
       " (3,\n",
       "  '0.036*\"keyboard\" + 0.032*\"mous\" + 0.026*\"button\" + 0.022*\"monitor\" + 0.018*\"key\" + 0.011*\"logitech\" + 0.009*\"batteri\" + 0.008*\"feel\" + 0.007*\"hand\" + 0.007*\"click\"'),\n",
       " (4,\n",
       "  '0.028*\"drive\" + 0.018*\"card\" + 0.013*\"usb\" + 0.012*\"comput\" + 0.010*\"gb\" + 0.009*\"instal\" + 0.008*\"window\" + 0.007*\"run\" + 0.007*\"hard\" + 0.007*\"file\"'),\n",
       " (5,\n",
       "  '0.014*\"get\" + 0.011*\"time\" + 0.009*\"would\" + 0.008*\"unit\" + 0.008*\"tri\" + 0.007*\"go\" + 0.006*\"radio\" + 0.006*\"thing\" + 0.006*\"back\" + 0.006*\"review\"'),\n",
       " (6,\n",
       "  '0.050*\"camera\" + 0.022*\"len\" + 0.011*\"pictur\" + 0.010*\"canon\" + 0.009*\"take\" + 0.009*\"mm\" + 0.008*\"great\" + 0.008*\"light\" + 0.008*\"photo\" + 0.008*\"good\"'),\n",
       " (7,\n",
       "  '0.026*\"sound\" + 0.019*\"good\" + 0.017*\"great\" + 0.016*\"price\" + 0.016*\"qualiti\" + 0.015*\"headphon\" + 0.010*\"ear\" + 0.008*\"music\" + 0.008*\"product\" + 0.008*\"much\"')]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
